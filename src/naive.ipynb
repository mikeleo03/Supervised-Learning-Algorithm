{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algoritma *Naive Bayes*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mari berkenalan dengan Algoritma Naive Bayes\n",
    "\n",
    "insert penjelasan here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mengimpor Pustaka"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada bagian ini akan diimpor beberapa pustaka yang akan digunakan untuk menyimulasikan Algoritma *K-Nearest Neighbor*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selain itu, akan dipanggil juga modul KNN yang telah dibangun *from scratch*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from algorithm.naiveBayes import NaiveBayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mengimpor *Dataset*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada bagian ini akan diimpor *dataset* yang sebelumnya telah terbagi menjadi `data_train.csv` dan `data_validation.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mengambil data train dan data validation\n",
    "df_train = pd.read_csv(\"../data/data_train.csv\")\n",
    "df_validation = pd.read_csv(\"../data/data_validation.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Pre-processing* Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tahap yang dilakukan meliputi pemisahan kolom target hingga melakukan standarisasi terhadap data sebelum dilakukan pemrosesan dengan Algoritma KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melakukan pemisahan kolom target\n",
    "# Menghapus baris dengan nilai yang tidak valid\n",
    "df_train = df_train[df_train.px_width != 0]\n",
    "df_train = df_train[df_train.px_height != 0]\n",
    "\n",
    "# Pada bagian ini, dipilih fitur dengan nilai korelasi diatas 0.1 melalui hasil EDA\n",
    "columns_to_exclude = [\"blue\", \"wifi\", \"three_g\", \"int_memory\", \"sc_w\", \"clock_speed\", \"sc_h\", \"talk_time\", \"m_dep\", \"four_g\", \"n_cores\", \"fc\", \"pc\", \"dual_sim\", \"touch_screen\", \"mobile_wt\", \"price_range\"]\n",
    "x_train = df_train.drop(columns=columns_to_exclude)\n",
    "y_train = df_train[\"price_range\"]\n",
    "\n",
    "x_test = df_validation.drop(columns=columns_to_exclude)\n",
    "y_test = df_validation[\"price_range\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dilakukan standarisasi dengan scaler yang dibuat mandiri\n",
    "from utils.scaler import Scaler\n",
    "\n",
    "scaler = Scaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hasil Pemrosesan Algoritma Naive Bayes yang Dibangun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Berikut adalah hasil pemrosesan Algoritma Naive Bayes yang dibangun *from scratch*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gunakan model KNN yang sebelumnya dibangun\n",
    "nb_scratch = NaiveBayes() \n",
    "\n",
    "# Lakukan fit model\n",
    "nb_scratch.fit(x_train, y_train)\n",
    "\n",
    "# Lakukan prediksi dengan data validation\n",
    "y_pred_scratch = nb_scratch.predict(x_test, 1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88       142\n",
      "           1       0.67      0.65      0.66       144\n",
      "           2       0.68      0.72      0.70       155\n",
      "           3       0.91      0.88      0.89       159\n",
      "\n",
      "    accuracy                           0.79       600\n",
      "   macro avg       0.79      0.78      0.78       600\n",
      "weighted avg       0.79      0.79      0.79       600\n",
      "\n",
      "Akurasi :  78.5 %\n"
     ]
    }
   ],
   "source": [
    "# Pengujian kualitas model dengan metrik\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred_scratch))\n",
    "print(\"Akurasi : \", 100 * np.round(accuracy_score(y_test, y_pred_scratch), 5), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hasil Pemrosesan Algoritma Naive Bayes Pembanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasil pemrosesan diatas akan dibandingkan dengan hasil yang diperoleh dari *library* scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pemanggilan model KNN dari scikit-learn\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "gnb = GaussianNB()\n",
    "y_pred = gnb.fit(x_train, y_train)\n",
    "y_pred_scikit = gnb.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88       142\n",
      "           1       0.67      0.65      0.66       144\n",
      "           2       0.68      0.72      0.70       155\n",
      "           3       0.91      0.88      0.89       159\n",
      "\n",
      "    accuracy                           0.79       600\n",
      "   macro avg       0.79      0.78      0.78       600\n",
      "weighted avg       0.79      0.79      0.79       600\n",
      "\n",
      "Akurasi :  78.5 %\n"
     ]
    }
   ],
   "source": [
    "# Pengujian kualitas model dengan metrik\n",
    "print(classification_report(y_test, y_pred_scikit))\n",
    "print(\"Akurasi : \", 100 * np.round(accuracy_score(y_test, y_pred_scikit), 5), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hasil yang diperoleh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Berdasarkan kedua hasil tersebut, diperoleh **hasil yang sama** antara nilai prediksi yang dihasilkan oleh model Naive Bayes yang dibangun *from scratch* dengan model yang dimiliki scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       143\n",
      "           1       1.00      1.00      1.00       140\n",
      "           2       1.00      1.00      1.00       163\n",
      "           3       1.00      1.00      1.00       154\n",
      "\n",
      "    accuracy                           1.00       600\n",
      "   macro avg       1.00      1.00      1.00       600\n",
      "weighted avg       1.00      1.00      1.00       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pengujian kualitas model dengan metrik\n",
    "print(classification_report(y_pred_scratch, y_pred_scikit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apakah sudah merupakan model yang terbaik?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OTW diubah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 400 candidates, totalling 4000 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB(var_smoothing=0.5647805074067556)\n"
     ]
    }
   ],
   "source": [
    "# Menggunakan grid search, cari nilai variable smoothing terbaik\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid_nb = {\n",
    "    'var_smoothing': np.logspace(0,-9, num=400)\n",
    "}\n",
    "bestNB = GridSearchCV(estimator=GaussianNB(), param_grid=param_grid_nb, verbose=1, cv=10, n_jobs=-1)\n",
    "bestNB.fit(x_train, y_train)\n",
    "print(bestNB.best_estimator_)\n",
    "best_param = bestNB.best_params_\n",
    "y_pred_scikit = bestNB.best_estimator_.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96       142\n",
      "           1       0.75      0.69      0.72       144\n",
      "           2       0.72      0.75      0.73       155\n",
      "           3       0.96      0.92      0.94       159\n",
      "\n",
      "    accuracy                           0.84       600\n",
      "   macro avg       0.84      0.84      0.84       600\n",
      "weighted avg       0.84      0.84      0.84       600\n",
      "\n",
      "Akurasi :  84.0 %\n"
     ]
    }
   ],
   "source": [
    "# Pengujian kualitas model dengan metrik\n",
    "print(classification_report(y_test, y_pred_scikit))\n",
    "print(\"Akurasi : \", 100 * np.round(accuracy_score(y_test, y_pred_scikit), 5), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gunakan model KNN yang sebelumnya dibangun\n",
    "nb_scratch = NaiveBayes() \n",
    "\n",
    "# Lakukan fit model\n",
    "nb_scratch.fit(x_train, y_train)\n",
    "\n",
    "# Lakukan prediksi dengan data validation, menggunakan var_smoothing terbaik yang ditemukan\n",
    "y_pred_scratch = nb_scratch.predict(x_test, 0.5647805074067556)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96       142\n",
      "           1       0.73      0.69      0.71       144\n",
      "           2       0.71      0.74      0.72       155\n",
      "           3       0.96      0.91      0.94       159\n",
      "\n",
      "    accuracy                           0.83       600\n",
      "   macro avg       0.83      0.83      0.83       600\n",
      "weighted avg       0.83      0.83      0.83       600\n",
      "\n",
      "Akurasi :  83.333 %\n"
     ]
    }
   ],
   "source": [
    "# Pengujian kualitas model dengan metrik\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred_scratch))\n",
    "print(\"Akurasi : \", 100 * np.round(accuracy_score(y_test, y_pred_scratch), 5), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Penyimpanan dan *Load* Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agar model dapat digunakan kembali, maka model harus dapat disimpan dan di-*load*. Berikut adalah implementasi penyimpanan model yang dilakukan menggunakan *library* pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Menyimpan model dalam pkl\n",
    "model_pkl_file = \"models/naive_bayes_model.pkl\"  \n",
    "\n",
    "with open(model_pkl_file, 'wb') as file:  \n",
    "    pickle.dump(nb_scratch, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Untuk membuktikan bahwa model berhasil tersimpan, berikut adalah pembuktian pemanggilan kembali hasil prediksi model yang disimpan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96       142\n",
      "           1       0.73      0.69      0.71       144\n",
      "           2       0.71      0.74      0.72       155\n",
      "           3       0.96      0.91      0.94       159\n",
      "\n",
      "    accuracy                           0.83       600\n",
      "   macro avg       0.83      0.83      0.83       600\n",
      "weighted avg       0.83      0.83      0.83       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load kembali model dari pkl\n",
    "with open(model_pkl_file, 'rb') as file:  \n",
    "    model = pickle.load(file)\n",
    "\n",
    "# Melakukan prediksi dengan model tersebut\n",
    "y_pickle = model.predict(x_test, 0.5647805074067556)\n",
    "\n",
    "# Menguji hasil akurasi model\n",
    "print(classification_report(y_test, y_pickle)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Terbukti bahwa model pkl yang disimpan berhasil untuk digunakan kembali."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Bonus] Submisi Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagian ini dikhususkan untuk pemrosesan data dan penggunaan model yang dibuat sebagai dasar membuat submisi pada Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impor dataset\n",
    "test_data = pd.read_csv('../data/test.csv')\n",
    "\n",
    "columns_to_exclude_new = [\"id\", \"blue\", \"wifi\", \"three_g\", \"int_memory\", \"sc_w\", \"clock_speed\", \"sc_h\", \"talk_time\", \"m_dep\", \"four_g\", \"n_cores\", \"fc\", \"pc\", \"dual_sim\", \"touch_screen\", \"mobile_wt\"]\n",
    "features = test_data.drop(columns=columns_to_exclude_new)\n",
    "\n",
    "# Gunakan model KNN yang sebelumnya dibangun\n",
    "nb_kaggle = NaiveBayes()\n",
    "\n",
    "# Lakukan fit model\n",
    "nb_kaggle.fit(x_train, y_train)\n",
    "\n",
    "# Lakukan prediksi dengan data validation\n",
    "feature_test = scaler.transform(features)\n",
    "predictions = nb_kaggle.predict(feature_test, 0.5647805074067556)\n",
    "\n",
    "# Membuat dataframe hasil\n",
    "result_df = pd.DataFrame({'id': test_data['id'], 'price_range': predictions})\n",
    "\n",
    "# Menyimpan dataframe dalam csv\n",
    "result_df.to_csv('../result/predictions-naive-bayes.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
