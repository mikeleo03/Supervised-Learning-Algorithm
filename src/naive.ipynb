{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algoritma *Naive Bayes*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mari berkenalan dengan Algoritma Naive Bayes\n",
    "\n",
    "Algoritma Naive Bayes merupakan algoritma *machine learning* yang berbasis pada probabilitas. Algoritma ini umumnya digunakan untuk melakukan klasifikasi. Naive Bayes bekerja dengan menentukan nilai probabilitas sebuah sample termasuk suatu label/kategori berdasarkan data yang diberikan. Perhitungan probabilitas ini menggunakan konsep *conditional probability*.\n",
    "\n",
    "*Conditional probability* adalah peluang terjadinya suatu kejadian apabila diketahui kejadian lain sudah berlangsung. Contohnya, peluang mendapatkan kartu ratu jika diketahui kartu tersebut adalah ratu padung sebesar 1/13, bukan 1/52 (jumlah kartu dalam dek lengkap). Peluang terjadinya A jika diketahui B terjadi dinotasikan sebagai P(A|B) dan bisa dihitung dengan rumus \n",
    "$$P(A|B) = \\frac{P(A ∩ B)}{P(B)}$$\n",
    " Rumus tersebut disebut sebagai Aturan Bayes.\n",
    "\n",
    "Naive Bayes menggunakan Aturan Bayes sebagai berikut (misalkan X merupakan data dan Y merupakan label) :\n",
    "$$P(X | Y) = \\frac{P(X ∩ Y)}{P(Y)}$$\n",
    "$$P(X ∩ Y) = P(X | Y) * P(Y)$$\n",
    "$$P(Y | X) = \\frac{P(X ∩ Y)} {P(X)} = \\frac{P(X | Y) * P(Y)}{P(X)}$$\n",
    "\n",
    "Umunya X terdiri dari lebih dari satu jenis data. Aturan Bayes biasa untuk kasus dengan lebih dari satu jenis data adalah : \n",
    "$$P((a,z)∣b)=\\frac{P(a,z,b)}{P(b)}=\\frac{P(z,b) * P(a∣(z,b))}{P(b)}=\\frac{P(b) * P(z∣b) * P(a∣(z,b))}{P(b)}=P(z∣b) * P(a∣(z,b))=P(a∣(z,b)) * P(z∣b)$$\n",
    "\n",
    "Untuk menyederhanakan perhitungan, Naive Bayes mengasumsikan masing-masing jenis data dalam X tidak saling memengaruhi (independen), sehingga perhitungannya berubah menjadi\n",
    "\n",
    "$$P(Y | X1, X2, ...Xn) = \\frac{P(X1 | Y) * P(X2 | Y) * ... * P(Xn | Y) * P(Y)}{P(X1) * P(X2) * ... * P(Xn)}$$\n",
    "\n",
    "P(Y) adalah peluang munculnya sebuah kategori Y dalam data, disebut juga *prior probability*. P(X1 | Y) * P(X2 | Y) * ... * P(Xn | Y) adalah perkalian seluruh kemungkinan data untuk label Y, disebut juga *probability of likelihood of evidence*. Pembagi merupakan hasil perkalian probabilitas masing-masing data atau disebut juga *probability of evidence*. Tujuan Naive Bayes adalah membandingkan probabilitas setiap kategori/label Y. Karena *probability of evidence* sama untuk setiap nilai Y yang mungkin, pembagi bisa diabaikan. Rumus akhir untuk perhitungan Naive Bayes adalah \n",
    "$$P(Y | X1, X2, ...Xn) = P(X1 | Y) * P(X2 | Y) * ... * P(Xn | Y) * P(Y)$$\n",
    "\n",
    "P(X1 | Y) dan peluang X yang lain biasanya berupa perbandingan banyak nilai X tersebut dibanding banyak seluruh nilai jenis yang bersesuaian untuk label Y. Oleh karena itu, Naive Bayes biasanya digunakan untuk klasifikasi dengan data diskrit. Tetapi, Naive Bayes masih bisa digunakan untuk data kontinu. Peluang nilai kontinu bisa dilakukan dengan diskretisasi data (misal membagi menjadi 4 range data) maupun dengan menggunakan rumus densitas distribusi tertentu. Dalam implementasi kali ini akan digunakan rumus densitas Gaussian. Rumus Gaussian ini mengasumsikan data berdistribusi normal. Rumus ini digunakan walau data tidak berdistribusi normal karena dari hasil percobaan memiliki hasil yang paling bagus. Rumus distribusi Gaussian adalah \n",
    "$$f(x) = \\frac{1}{σ*\\sqrt{2π}} * e ^ {-0.5 *(\\frac{x-μ}{σ}) ^ 2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mengimpor Pustaka"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada bagian ini akan diimpor beberapa pustaka yang akan digunakan untuk menyimulasikan Algoritma *Naive Bayes*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selain itu, akan dipanggil juga modul Naive Bayes yang telah dibangun *from scratch*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from algorithm.naiveBayes import NaiveBayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mengimpor *Dataset*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada bagian ini akan diimpor *dataset* yang sebelumnya telah terbagi menjadi `data_train.csv` dan `data_validation.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mengambil data train dan data validation\n",
    "df_train = pd.read_csv(\"../data/data_train.csv\")\n",
    "df_validation = pd.read_csv(\"../data/data_validation.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Pre-processing* Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tahap yang dilakukan meliputi pemisahan kolom target hingga melakukan standarisasi terhadap data sebelum dilakukan pemrosesan dengan Algoritma Naive Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melakukan pemisahan kolom target\n",
    "# Menghapus baris dengan nilai yang tidak valid\n",
    "df_train = df_train[df_train.px_width != 0]\n",
    "df_train = df_train[df_train.px_height != 0]\n",
    "\n",
    "# Pada bagian ini, dipilih fitur dengan nilai korelasi diatas 0.1 melalui hasil EDA\n",
    "columns_to_exclude = [\"blue\", \"wifi\", \"three_g\", \"int_memory\", \"sc_w\", \"clock_speed\", \"sc_h\", \"talk_time\", \"m_dep\", \"four_g\", \"n_cores\", \"fc\", \"pc\", \"dual_sim\", \"touch_screen\", \"mobile_wt\", \"price_range\"]\n",
    "x_train = df_train.drop(columns=columns_to_exclude)\n",
    "y_train = df_train[\"price_range\"]\n",
    "\n",
    "x_test = df_validation.drop(columns=columns_to_exclude)\n",
    "y_test = df_validation[\"price_range\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dilakukan standarisasi dengan scaler yang dibuat mandiri\n",
    "from utils.scaler import Scaler\n",
    "\n",
    "scaler = Scaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hasil Pemrosesan Algoritma Naive Bayes yang Dibangun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Berikut adalah hasil pemrosesan Algoritma Naive Bayes yang dibangun *from scratch*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gunakan model KNN yang sebelumnya dibangun\n",
    "nb_scratch = NaiveBayes() \n",
    "\n",
    "# Lakukan fit model\n",
    "nb_scratch.fit(x_train, y_train)\n",
    "\n",
    "# Lakukan prediksi dengan data validation\n",
    "y_pred_scratch = nb_scratch.predict(x_test, 1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88       142\n",
      "           1       0.67      0.65      0.66       144\n",
      "           2       0.68      0.72      0.70       155\n",
      "           3       0.91      0.88      0.89       159\n",
      "\n",
      "    accuracy                           0.79       600\n",
      "   macro avg       0.79      0.78      0.78       600\n",
      "weighted avg       0.79      0.79      0.79       600\n",
      "\n",
      "Akurasi :  78.5 %\n"
     ]
    }
   ],
   "source": [
    "# Pengujian kualitas model dengan metrik\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred_scratch))\n",
    "print(\"Akurasi : \", 100 * np.round(accuracy_score(y_test, y_pred_scratch), 5), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hasil Pemrosesan Algoritma Naive Bayes Pembanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasil pemrosesan diatas akan dibandingkan dengan hasil yang diperoleh dari *library* scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pemanggilan model KNN dari scikit-learn\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "gnb = GaussianNB()\n",
    "y_pred = gnb.fit(x_train, y_train)\n",
    "y_pred_scikit = gnb.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88       142\n",
      "           1       0.67      0.65      0.66       144\n",
      "           2       0.68      0.72      0.70       155\n",
      "           3       0.91      0.88      0.89       159\n",
      "\n",
      "    accuracy                           0.79       600\n",
      "   macro avg       0.79      0.78      0.78       600\n",
      "weighted avg       0.79      0.79      0.79       600\n",
      "\n",
      "Akurasi :  78.5 %\n"
     ]
    }
   ],
   "source": [
    "# Pengujian kualitas model dengan metrik\n",
    "print(classification_report(y_test, y_pred_scikit))\n",
    "print(\"Akurasi : \", 100 * np.round(accuracy_score(y_test, y_pred_scikit), 5), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hasil yang diperoleh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Berdasarkan kedua hasil tersebut, diperoleh **hasil yang sama** antara nilai prediksi yang dihasilkan oleh model Naive Bayes yang dibangun *from scratch* dengan model yang dimiliki scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       143\n",
      "           1       1.00      1.00      1.00       140\n",
      "           2       1.00      1.00      1.00       163\n",
      "           3       1.00      1.00      1.00       154\n",
      "\n",
      "    accuracy                           1.00       600\n",
      "   macro avg       1.00      1.00      1.00       600\n",
      "weighted avg       1.00      1.00      1.00       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pengujian kualitas model dengan metrik\n",
    "print(classification_report(y_pred_scratch, y_pred_scikit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apakah sudah merupakan model yang terbaik?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Belum tentu! Perhitungan distribusi Gaussian memerlukan nilai variansi suatu kolom, namun ada kemungkinan nilai variansi tersebut 0. Nilai variansi 0 akan menyebabkan fungsi distribusi Gaussian tidak valid (ada pembagian dengan 0). Apabila jumlah data kita cukup banyak, kita bisa menambah variansi setiap data dengan sebuah nilai yang relatif kecil sehingga tidak ada variansi yang bernilai 0. Jumlah data yang banyak berarti penambahan tersebut tidak akan memengaruhi hasil secara signifikan. Oleh karena itu, fungsi *Gaussian Naive Bayes* dalam *library* scikit-learn memiliki parameter var_smoothing. Nilai var_smoothing ini akan dikali dengan nilai maksimum dari variansi seluruh data training untuk mendapat epsilon. Nilai epsilon ini yang kemudian ditambahkan ke variansi masing-masing kolom data.\n",
    "\n",
    "*Variance smoothing* ini bisa meningkatkan akurasi hasil algoritma *Naive Bayes* jika nilainya optimal. Oleh karena itu, diperlukan nilai var_smoothing yang optimal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memperkenalkan *Cross-validation*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Menemukan nilai terbaik untuk hyperparameter 'var_smoothing' di *Naive Bayes* melibatkan proses yang disebut *hyperparameter tuning*. Salah satu pendekatan yang umum adalah dengan menggunakan *cross-validation*.\n",
    "Berikut adalah detail prosedurnya\n",
    "1. Pemilihan Jumlah Subset (*Fold*)<br/> \n",
    "*Dataset* dibagi menjadi beberapa subset yang disebut \"fold.\" Misalnya, dalam *5-fold cross-validation*, *dataset* dibagi menjadi 5 bagian. Proses pelatihan dan pengujian akan dilakukan sebanyak 5 kali, di mana setiap *fold* digunakan sebagai subset pengujian satu kali, dan sisanya digunakan sebagai subset pelatihan.<br/>\n",
    "2. Pelatihan dan Pengujian Berulang<br/> \n",
    "Model pembelajaran mesin dilatih pada subset pelatihan dan diuji pada subset pengujian untuk setiap iterasi *cross-validation*. Proses ini dilakukan sebanyak jumlah *fold* yang telah ditentukan. <br/>\n",
    "3. Perhitungan Metrik Kinerja<br/> \n",
    "Metrik kinerja seperti akurasi, presisi, *recall*, atau *F1-score* dihitung untuk setiap iterasi *cross-validation*. Metrik ini memberikan gambaran tentang seberapa baik model berkinerja pada berbagai subset data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Berikut adalah prosedur yang dilakukan untuk melakukan *cross-validation* dengan menggunakan *library* milik scikit-learn. Secara umum proses yang dilakukan adalah *Grid Search* dengan rentang nilai yang terdistribusi merata dalam skala log antara 0 sampai -9, dengan jumlah 400 nilai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 400 candidates, totalling 4000 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB(var_smoothing=0.5647805074067556)\n"
     ]
    }
   ],
   "source": [
    "# Menggunakan grid search, cari nilai variable smoothing terbaik\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid_nb = {\n",
    "    'var_smoothing': np.logspace(0,-9, num=400)\n",
    "}\n",
    "bestNB = GridSearchCV(estimator=GaussianNB(), param_grid=param_grid_nb, verbose=1, cv=10, n_jobs=-1)\n",
    "bestNB.fit(x_train, y_train)\n",
    "print(bestNB.best_estimator_)\n",
    "best_param = bestNB.best_params_['var_smoothing']\n",
    "y_pred_scikit = bestNB.best_estimator_.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setelah mendapatkan nilai var_smoothing dan model terbaik, mari kembali lakukan pengujian menggunakan Algoritma *Naive Bayes* yang telah dibangun sebelumnya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96       142\n",
      "           1       0.75      0.69      0.72       144\n",
      "           2       0.72      0.75      0.73       155\n",
      "           3       0.96      0.92      0.94       159\n",
      "\n",
      "    accuracy                           0.84       600\n",
      "   macro avg       0.84      0.84      0.84       600\n",
      "weighted avg       0.84      0.84      0.84       600\n",
      "\n",
      "Akurasi :  84.0 %\n"
     ]
    }
   ],
   "source": [
    "# Pengujian kualitas model dengan metrik\n",
    "print(classification_report(y_test, y_pred_scikit))\n",
    "print(\"Akurasi : \", 100 * np.round(accuracy_score(y_test, y_pred_scikit), 5), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gunakan model KNN yang sebelumnya dibangun\n",
    "nb_scratch = NaiveBayes() \n",
    "\n",
    "# Lakukan fit model\n",
    "nb_scratch.fit(x_train, y_train)\n",
    "\n",
    "# Lakukan prediksi dengan data validation, menggunakan var_smoothing terbaik yang ditemukan\n",
    "y_pred_scratch = nb_scratch.predict(x_test, best_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96       142\n",
      "           1       0.75      0.69      0.72       144\n",
      "           2       0.72      0.75      0.73       155\n",
      "           3       0.96      0.92      0.94       159\n",
      "\n",
      "    accuracy                           0.84       600\n",
      "   macro avg       0.84      0.84      0.84       600\n",
      "weighted avg       0.84      0.84      0.84       600\n",
      "\n",
      "Akurasi :  84.0 %\n"
     ]
    }
   ],
   "source": [
    "# Pengujian kualitas model dengan metrik\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred_scratch))\n",
    "print(\"Akurasi : \", 100 * np.round(accuracy_score(y_test, y_pred_scratch), 5), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Terlihat bahwa dengan melakukan cross-validation pada rentang nilai var_smoothing tersebut, diperoleh nilai var_smoothing terbaik adalah 0.5647805074067556. Angka ini meningkat dari akurasi sebelumnya!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Penyimpanan dan *Load* Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agar model dapat digunakan kembali, maka model harus dapat disimpan dan di-*load*. Berikut adalah implementasi penyimpanan model yang dilakukan menggunakan *library* pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Menyimpan model dalam pkl\n",
    "model_pkl_file = \"models/naive_bayes_model.pkl\"  \n",
    "\n",
    "with open(model_pkl_file, 'wb') as file:  \n",
    "    pickle.dump(nb_scratch, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Untuk membuktikan bahwa model berhasil tersimpan, berikut adalah pembuktian pemanggilan kembali hasil prediksi model yang disimpan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96       142\n",
      "           1       0.75      0.69      0.72       144\n",
      "           2       0.72      0.75      0.73       155\n",
      "           3       0.96      0.92      0.94       159\n",
      "\n",
      "    accuracy                           0.84       600\n",
      "   macro avg       0.84      0.84      0.84       600\n",
      "weighted avg       0.84      0.84      0.84       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load kembali model dari pkl\n",
    "with open(model_pkl_file, 'rb') as file:  \n",
    "    model = pickle.load(file)\n",
    "\n",
    "# Melakukan prediksi dengan model tersebut\n",
    "y_pickle = model.predict(x_test, 0.5647805074067556)\n",
    "\n",
    "# Menguji hasil akurasi model\n",
    "print(classification_report(y_test, y_pickle)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Terbukti bahwa model pkl yang disimpan berhasil untuk digunakan kembali."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Bonus] Submisi Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagian ini dikhususkan untuk pemrosesan data dan penggunaan model yang dibuat sebagai dasar membuat submisi pada Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impor dataset\n",
    "test_data = pd.read_csv('../data/test.csv')\n",
    "\n",
    "columns_to_exclude_new = [\"id\", \"blue\", \"wifi\", \"three_g\", \"int_memory\", \"sc_w\", \"clock_speed\", \"sc_h\", \"talk_time\", \"m_dep\", \"four_g\", \"n_cores\", \"fc\", \"pc\", \"dual_sim\", \"touch_screen\", \"mobile_wt\"]\n",
    "features = test_data.drop(columns=columns_to_exclude_new)\n",
    "\n",
    "# Gunakan model KNN yang sebelumnya dibangun\n",
    "nb_kaggle = NaiveBayes()\n",
    "\n",
    "# Lakukan fit model\n",
    "nb_kaggle.fit(x_train, y_train)\n",
    "\n",
    "# Lakukan prediksi dengan data validation\n",
    "feature_test = scaler.transform(features)\n",
    "predictions = nb_kaggle.predict(feature_test, 0.5647805074067556)\n",
    "\n",
    "# Membuat dataframe hasil\n",
    "result_df = pd.DataFrame({'id': test_data['id'], 'price_range': predictions})\n",
    "\n",
    "# Menyimpan dataframe dalam csv\n",
    "result_df.to_csv('../result/predictions-naive-bayes.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
